// src/cached_scraper_db.rs
use crate::dlsite_scraper::{Scraper, ScraperError}; // ä½ å·²æœ‰çš„æ¨¡å—
use rusqlite::{params, Connection};
use rusqlite::OptionalExtension;
use serde::{Deserialize, Serialize};
use thiserror::Error;
use crate::work_metadata::WorkMetadata;
use crate::dlsite::Dlsite;
use crate::log_to_ui;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct WorkMeta {
    pub rjcode: String,
    pub title: String,
    pub maker: String,
    pub date: Option<String>,
    pub cover_url: Option<String>,
}

#[derive(Error, Debug)]
pub enum CacheError {
    #[error("æ•°æ®åº“é”™è¯¯: {0}")]
    Db(#[from] rusqlite::Error),
    #[error("åºåˆ—åŒ–é”™è¯¯: {0}")]
    Serde(#[from] serde_json::Error),
    #[error("çˆ¬è™«é”™è¯¯: {0}")]
    Scraper(#[from] ScraperError),
}

pub struct CachedScraperDb {
    conn: Connection,
}

impl CachedScraperDb {
    pub fn new(db_path: &str) -> Result<Self, CacheError> {
        let conn = Connection::open(db_path)?;
        conn.execute_batch(
            "CREATE TABLE IF NOT EXISTS work_cache (
                rjcode TEXT PRIMARY KEY,
                data TEXT NOT NULL,
                fetched_at INTEGER NOT NULL
            );",
        )?;
        Ok(Self { conn })
    }

        /// è·å–æˆ–çˆ¬å–æ•°æ®ï¼ˆä¸»æ¥å£ï¼‰
    pub fn get_or_fetch(
        &self,
        scraper: impl Scraper,
        rjcode: &str,
        logs: &std::sync::Arc<std::sync::Mutex<Vec<String>>>,
    ) -> Result<WorkMeta, CacheError> {
        if let Some(cached) = self.get(rjcode)? {
            log_to_ui!(logs,"ğŸ§Š ç¼“å­˜å‘½ä¸­ï¼š{}", rjcode);
            return Ok(cached);
        }
        log_to_ui!(logs,"ğŸ”¥ æœªå‘½ä¸­ç¼“å­˜ï¼Œå¼€å§‹çˆ¬å–ï¼š{}", rjcode);

        // âœ… ä½¿ç”¨ Dlsite å°è£…æŠ“å–é€»è¾‘
        let dlsite = Dlsite::new(scraper);
        let metadata: WorkMetadata = dlsite.fetch_metadata(rjcode)?;

        // âœ… å°† WorkMetadata æ˜ å°„ä¸º WorkMeta
        let meta = WorkMeta {
            rjcode: rjcode.to_string(),
            title: metadata.title,
            maker: metadata.circle.unwrap_or_default(),
            date: metadata.release_date,
            cover_url: None, // WorkMetadata æ²¡æœ‰ cover_url å­—æ®µ
        };

        self.insert(&meta)?;
        Ok(meta)
    }

    fn get(&self, rjcode: &str) -> Result<Option<WorkMeta>, CacheError> {
        let mut stmt = self
            .conn
            .prepare("SELECT data FROM work_cache WHERE rjcode = ?1")?;
        let row: Option<String> = stmt
            .query_row(params![rjcode], |row| row.get(0))
            .optional()?;

        match row {
            Some(json) => Ok(Some(serde_json::from_str(&json)?)),
            None => Ok(None),
        }
    }

    fn insert(&self, meta: &WorkMeta) -> Result<(), CacheError> {
        let json = serde_json::to_string(meta)?;
        self.conn.execute(
            "INSERT OR REPLACE INTO work_cache (rjcode, data, fetched_at) VALUES (?1, ?2, strftime('%s','now'))",
            params![meta.rjcode, json],
        )?;
        Ok(())
    }
}

// ç®€åŒ–çš„æå–å·¥å…·å‡½æ•°
fn extract_between<'a>(html: &'a str, start: &str, end: &str) -> Option<&'a str> {
    let s = html.find(start)? + start.len();
    let e = html[s..].find(end)? + s;
    Some(&html[s..e])
}
