// src/scraper/scraper.rs

use std::collections::HashMap;
use thiserror::Error;
use std::path::Path;
use std::fs;
use tokio::fs as async_fs;
use ureq::Error; // Needed for Error
use ureq::Agent;
use std::time::Duration;
use std::io::Read;
use headless_chrome::Browser;
use anyhow::Context;

#[derive(Debug, Error)]
pub enum ScraperError {
    #[error("HTTP è¯·æ±‚å¤±è´¥: {0}")]
    HttpRequestError(String),
    #[error("ä½œå“ä¸å­˜åœ¨")]
    NotFound,
    #[error("é¡µé¢è§£æå¤±è´¥: {0}")]
    ParseError(String),
}

/// çˆ¬è™« Traitï¼šå¯å®ç°ä¸ºå„ç§ç«™ç‚¹çš„çˆ¬è™«
pub trait Scraper {
    fn fetch_page(&self, url: &str) -> Result<String, ScraperError>;
    /// ä¸‹è½½å°é¢å›¾åƒï¼ˆjpgï¼‰ï¼Œä¿å­˜ä¸º {ç›®æ ‡ç›®å½•}/cover.jpg
    fn download_cover<'a>(&'a self, rjcode: &'a str, dest_dir: &'a std::path::Path) -> std::pin::Pin<Box<dyn std::future::Future<Output = Option<()>> + Send + 'a>>;
    fn fetch_page_json(&self, url: &str) -> Result<serde_json::Value, ScraperError>;
}

/// é»˜è®¤å®ç°ï¼Œç”¨äºæŠ“å–DLsiteé¡µé¢
pub struct DlsiteScraper {
    headers: HashMap<String, String>,
}

impl DlsiteScraper {
    pub fn new() -> Self {
        let mut headers = HashMap::new();
        headers.insert("User-Agent".into(), "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114 Safari/537.36".into());
        headers.insert("Accept-Language".into(), "ja-JP".into());

        DlsiteScraper { headers }
    }
}

impl Scraper for DlsiteScraper {
    fn fetch_page(&self, url: &str) -> Result<String, ScraperError> {
        println!("ğŸŒ å¼€å§‹è¯·æ±‚é¡µé¢: {}", url); // ğŸ§ª 1. çœ‹æ˜¯å¦è°ƒç”¨äº†

        // åˆ›å»º Agentï¼ˆå¦‚éœ€ä»£ç†ï¼Œå¯ç»§ç»­æ·»åŠ é…ç½®ï¼‰
        let agent = Agent::new_with_defaults();

        // æ„å»ºè¯·æ±‚å¹¶é™„åŠ è‡ªå®šä¹‰ headers
        let mut request = agent.get(url);
        for (key, value) in &self.headers {
            request = request.header(key, value);
        }

        // ğŸ§ª 2. å°è¯•å‘é€è¯·æ±‚
        println!("ğŸš€ å‘é€è¯·æ±‚ä¸­...");
        let mut response = match request.call() {
            Ok(resp) => {
                println!("âœ… æ”¶åˆ°å“åº”: {} {}", resp.status(), resp.status());
                resp
            }
            Err(ureq::Error::StatusCode(code)) => {
                println!("âŒ çŠ¶æ€ç é”™è¯¯: {}", code);
                if code == 404 || code == 410 {
                    return Err(ScraperError::NotFound);
                }
                return Err(ScraperError::HttpRequestError(format!("çŠ¶æ€ç é”™è¯¯: {}", code)));
            }
            Err(e) => {
                println!("âŒ è¯·æ±‚å¤±è´¥: {}", e);
                return Err(ScraperError::HttpRequestError(format!("è¯·æ±‚å¤±è´¥: {}", e)));
            }
        };

        // ğŸ§ª 3. å°è¯•è¯»å–å“åº”å†…å®¹
        println!("ğŸ“– æ­£åœ¨è¯»å–å“åº”å†…å®¹...");
        let body = match response.body_mut().read_to_string() {
            Ok(s) => s,
            Err(e) => {
                println!("âŒ è¯»å–å“åº”å¤±è´¥: {}", e);
                return Err(ScraperError::HttpRequestError(format!("è¯»å–å“åº”å¤±è´¥: {}", e)));
            }
        };

        if body.contains("ã“ã®ä½œå“ã¯å­˜åœ¨ã—ã¾ã›ã‚“") {
            println!("âš ï¸ é¡µé¢æ˜¾ç¤ºä½œå“ä¸å­˜åœ¨");
            return Err(ScraperError::NotFound);
        }
        Ok(body)
    }


    fn fetch_page_json(&self, url: &str) -> Result<serde_json::Value, ScraperError> {
        println!("ğŸŒ è¯·æ±‚é¡µé¢: {}", url);

        let mut req = ureq::get(url);
        for (k, v) in &self.headers {
            req = req.header(k, v);
        }

        let mut response = req.call().map_err(|e| {
            println!("âŒ è¯·æ±‚å¤±è´¥: {}", e);
            match e {
                ureq::Error::StatusCode(code) if code == 404 || code == 410 => ScraperError::NotFound,
                ureq::Error::StatusCode(code) => {
                    ScraperError::HttpRequestError(format!("çŠ¶æ€ç é”™è¯¯: {}", code))
                }
                _ => ScraperError::HttpRequestError(format!("{}", e)),
            }
        })?;

        println!("âœ… çŠ¶æ€: {}", response.status());

        let body = response.body_mut().read_to_string().map_err(|e| {
            println!("âŒ è¯»å–å¤±è´¥: {}", e);
            ScraperError::HttpRequestError(format!("{}", e))
        })?;

        // å°è¯•è§£æå®Œæ•´ JSON å­—ç¬¦ä¸²
        let json: serde_json::Value = serde_json::from_str(&body).map_err(|e| {
            println!("âŒ JSON è§£æå¤±è´¥: {}", e);
            ScraperError::HttpRequestError(format!("è§£æ JSON å¤±è´¥: {}", e))
        })?;

        if json.is_array() {
            println!("âœ… JSON æ•°ç»„è§£ææˆåŠŸï¼Œå…± {} é¡¹", json.as_array().unwrap().len());
            Ok(json)
        } else {
            Err(ScraperError::HttpRequestError(
                "è¿”å›çš„ JSON ä¸æ˜¯æ•°ç»„".into(),
            ))
        }
    }

    /// ä¸‹è½½å°é¢å›¾åƒï¼ˆjpgï¼‰ï¼Œä¿å­˜ä¸º {ç›®æ ‡ç›®å½•}/cover.jpg
    fn download_cover<'a>(&'a self, rjcode: &'a str, dest_dir: &'a Path)
        -> std::pin::Pin<Box<dyn std::future::Future<Output = Option<()>> + Send + 'a>>
    {
        Box::pin(async move {
            if !rjcode.starts_with("RJ") || rjcode.len() < 5 {
                println!("éæ³• RJ ç ï¼š{}", rjcode);
                return None;
            }


            let numeric = rjcode.get(2..7)?.parse::<u32>().ok()?; // å– 01240
            let incremented = numeric + 1;                        // åŠ ä¸€ï¼Œå¾—åˆ° 01241
            let dir = format!("RJ{:05}000", incremented);          // æ‹¼ RJ0124100
            let url = format!(
                "https://img.dlsite.jp/modpub/images2/work/doujin/{}/{}_img_main.jpg",
                dir, rjcode
            );
            println!("{}",url);

        let client = reqwest::Client::new();
        let resp = match client
            .get(&url)
            .header("User-Agent", "Mozilla/5.0")
            .send()
            .await
        {
            Ok(r) => r,
            Err(e) => {
                println!("ä¸‹è½½å¤±è´¥ï¼š{}ï¼Œé”™è¯¯ï¼š{}", url, e);
                return None;
            }
        };

            if !resp.status().is_success() {
                println!("è¯·æ±‚å¤±è´¥ï¼š{} çŠ¶æ€ç  {}", url, resp.status());
                return None;
            }

            let img_bytes = match resp.bytes().await {
                Ok(b) => b,
                Err(e) => {
                    println!("è¯»å–å“åº”å­—èŠ‚å¤±è´¥: {}", e);
                    return None;
                }
            };

            let save_path = dest_dir.join("cover.jpg");
            if let Err(e) = async_fs::write(&save_path, &img_bytes).await {
                println!("ä¿å­˜å›¾åƒå¤±è´¥ï¼š{}ï¼Œé”™è¯¯ï¼š{}", save_path.display(), e);
                return None;
            }

            Some(())
        })
    }

}


